{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "Examen.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerardcebria/Deep-learning-examen/blob/main/Examen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prospective-america"
      },
      "source": [
        "Dado que el entrenamiento de redes neuronales es una tarea  muy costosa, **se recomienda ejecutar el notebooks en [Google Colab](https://colab.research.google.com)**, por supuesto también se puede ejecutar en local.\n",
        "\n",
        "Al entrar en [Google Colab](https://colab.research.google.com) bastará con hacer click en `upload` y subir este notebook. No olvide luego descargarlo en `File->Download .ipynb`\n",
        "\n",
        "**El examen deberá ser entregado con las celdas ejecutadas, si alguna celda no está ejecutadas no se contará.**"
      ],
      "id": "prospective-america"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "novel-stewart"
      },
      "source": [
        "El examen se divide en tres partes, con la puntuación que se indica a continuación. La puntuación máxima será 10.\n",
        "\n",
        "- [Actividad 1: Redes Densas](#actividad_1): 4 pts\n",
        "    - Correcta normalización: máximo de 0.25 pts\n",
        "    - [Cuestión 1](#1.1): 1 pt\n",
        "    - [Cuestión 2](#1.2): 1 pt\n",
        "    - [Cuestión 3](#1.3): 0.5 pts\n",
        "    - [Cuestión 4](#1.4): 0.25 pts\n",
        "    - [Cuestión 5](#1.5): 0.25 pts\n",
        "    - [Cuestión 6](#1.6): 0.25 pts\n",
        "    - [Cuestión 7](#1.7): 0.25 pts\n",
        "    - [Cuestión 8](#1.8): 0.25 pts\n",
        "\n",
        "\n",
        "- [Actividad 2: Redes Convolucionales](#actividad_2): 4 pts\n",
        "    - [Cuestión 1](#2.1): 1 pt\n",
        "    - [Cuestión 2](#2.2): 1.5 pt\n",
        "    - [Cuestión 3](#2.3): 0.5 pts\n",
        "    - [Cuestión 4](#2.4): 0.25 pts\n",
        "    - [Cuestión 5](#2.5): 0.25 pts\n",
        "    - [Cuestión 6](#2.6): 0.25 pts\n",
        "    - [Cuestión 7](#2.7): 0.25 pts\n",
        "    \n",
        "    \n",
        "- [Actividad 3: Redes Recurrentes](#actividad_3): 2 pts\n",
        "    - [Cuestión 1](#3.1): 0.5 pt\n",
        "    - [Cuestión 2](#3.2): 0.5 pt\n",
        "    - [Cuestión 3](#3.3): 0.5 pts\n",
        "    - [Cuestión 4](#3.4): 0.25 pts\n",
        "    - [Cuestión 5](#3.5): 0.25 pts\n",
        "\n"
      ],
      "id": "novel-stewart"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prompt-developer"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "id": "prompt-developer",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vocal-correction"
      },
      "source": [
        "<a name='actividad_1'></a>\n",
        "# Actividad 1: Redes Densas\n",
        "\n",
        "Para esta primera actividad vamos a utilizar el [boston housing dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html). Con el que trataremos de predecir el precio de una casa con 13 features.\n",
        "\n",
        "**Puntuación**: \n",
        "\n",
        "Normalizar las features correctamente (x_train, x_test): 0.1 pts , 0.25 si se normalizan con el [Normalization layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) de Keras. Ejemplo de uso: [Introduction_to_RNN_Time_Series](https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb)\n",
        "\n",
        "```python\n",
        "tf.keras.layers.experimental.preprocessing.Normalization(\n",
        "    axis=-1, dtype=None, mean=None, variance=None, **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "- Correcta normalización: máximo de 0.25 pts\n",
        "- [Cuestión 1](#1.1): 1 pt\n",
        "- [Cuestión 2](#1.2): 1 pt\n",
        "- [Cuestión 3](#1.3): 0.5 pts\n",
        "- [Cuestión 4](#1.4): 0.25 pts\n",
        "- [Cuestión 5](#1.5): 0.25 pts\n",
        "- [Cuestión 6](#1.6): 0.25 pts\n",
        "- [Cuestión 7](#1.7): 0.25 pts\n",
        "- [Cuestión 8](#1.8): 0.25 pts\n",
        "\n"
      ],
      "id": "vocal-correction"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "presidential-milan",
        "outputId": "09b9817c-7322-4bfe-968e-d18700a7f171"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path='boston_housing.npz',\n",
        "    test_split=0.2,\n",
        ")\n",
        "print('x_train, y_train shapes:', x_train.shape, y_train.shape)\n",
        "print('x_test, y_test shapes:', x_train.shape, y_train.shape)\n",
        "print('Some prices: ', y_train[:5])"
      ],
      "id": "presidential-milan",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train, y_train shapes: (404, 13) (404,)\n",
            "x_test, y_test shapes: (404, 13) (404,)\n",
            "Some prices:  [15.2 42.3 50.  21.1 17.7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "painted-extreme"
      },
      "source": [
        "## Si quiere, puede normalizar las features"
      ],
      "id": "painted-extreme",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "underlying-planner"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "## Cuestión 1: Cree un modelo secuencial que contenga 4 capas ocultas(hidden layers), con más de 60 neuronas  por capa, sin regularización y obtenga los resultados.\n",
        "\n",
        "Puntuación: \n",
        "- Obtener el modelo correcto: 0.8 pts\n",
        "- Compilar el modelo: 0.1pts\n",
        "- Acertar con la función de pérdida: 0.1 pts"
      ],
      "id": "underlying-planner"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "working-shade"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "# Código aquí\n",
        "model.add(keras.layers.Dense(61, input_shape=(13, ), activation='sigmoid'))\n",
        "model.add(keras.layers.Dense(61, activation='sigmoid'))\n",
        "model.add(keras.layers.Dense(61, activation='sigmoid'))\n",
        "model.add(keras.layers.Dense(61, activation='sigmoid'))"
      ],
      "id": "working-shade",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mobile-change"
      },
      "source": [
        "# Compilación del modelo\n",
        "# Código aquí\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )"
      ],
      "id": "mobile-change",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "rotary-credits",
        "outputId": "159e4276-d798-4f98-dd56-ddc861d6d91b"
      },
      "source": [
        "# No modifique el código\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=200,\n",
        "          batch_size=32,\n",
        "          validation_split=0.2,\n",
        "          verbose=1)"
      ],
      "id": "rotary-credits",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-eddff633160d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1608 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4979 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:174 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((None, 61) vs (None, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "descending-letters"
      },
      "source": [
        "# No modifique el código\n",
        "results = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "descending-letters",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raised-delivery"
      },
      "source": [
        "<a name='1.2'></a>\n",
        "## Cuestión 2: Utilice el mismo modelo de la cuestión anterior pero añadiendo al menos dos técnicas distinas de regularización.\n",
        "\n",
        "Ejemplos de regularización: [Prevent_Overfitting.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Prevent_Overfitting.ipynb)\n",
        "\n",
        "Puntuación:\n",
        "\n",
        "- Obtener el modelo con la regularización: 0.8 pts\n",
        "- Obtener un `test loss` inferior al anterior: 0.2 pts\n"
      ],
      "id": "raised-delivery"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hired-ground"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "# Código aquí\n",
        "..."
      ],
      "id": "hired-ground",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "focal-traffic"
      },
      "source": [
        "# Compilación del modelo\n",
        "# Código aquí\n",
        "model.compile(...)"
      ],
      "id": "focal-traffic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "338f8622"
      },
      "source": [
        "batch_size=..."
      ],
      "id": "338f8622",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prostate-instrumentation"
      },
      "source": [
        "# No modifique el código\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=200,\n",
        "          batch_size=batch_size,\n",
        "          validation_split=0.2,\n",
        "          verbose=1)"
      ],
      "id": "prostate-instrumentation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "friendly-powell"
      },
      "source": [
        "# No modifique el código\n",
        "results = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "friendly-powell",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "british-vegetation"
      },
      "source": [
        "<a name='1.3'></a>\n",
        "## Cuestión 3: Utilice el mismo modelo de la cuestión anterior pero añadiendo un callback de early stopping. Obtenga un test loss inferior al del modelo anterior"
      ],
      "id": "british-vegetation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "precise-finish"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "# Código aquí\n",
        "..."
      ],
      "id": "precise-finish",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blond-telephone"
      },
      "source": [
        "# Compilación del modelo\n",
        "# Código aquí\n",
        "model.compile(...)"
      ],
      "id": "blond-telephone",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "subsequent-roads"
      },
      "source": [
        "## definir el early stopping callback\n",
        "# Código aquí\n",
        "...\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=200,\n",
        "          batch_size=32,\n",
        "          validation_split=0.2,\n",
        "          verbose=1,\n",
        "          callbacks=[...]) # Código aquí"
      ],
      "id": "subsequent-roads",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pressing-object"
      },
      "source": [
        "# No modifique el código\n",
        "results = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "pressing-object",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "addressed-lesbian"
      },
      "source": [
        "<a name='1.4'></a>\n",
        "## Cuestión 4: ¿Podría haberse usado otra función de activación de la neurona de salida? En caso afirmativo especifíquela."
      ],
      "id": "addressed-lesbian"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruled-silicon"
      },
      "source": [
        ""
      ],
      "id": "ruled-silicon"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "robust-christianity"
      },
      "source": [
        "<a name='1.5'></a>\n",
        "## Cuestión 5:  ¿Qué es lo que una neurona calcula?\n",
        "\n",
        "**a)** Una función de activación seguida de una suma ponderada  de las entradas.\n",
        "\n",
        "**b)** Una suma ponderada  de las entradas seguida de una función de activación.\n",
        "\n",
        "**c)** Una función de pérdida, definida sobre el target.\n",
        "\n",
        "**d)** Ninguna  de las anteriores es correcta\n"
      ],
      "id": "robust-christianity"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joined-burden"
      },
      "source": [
        "Respuesta:\n",
        "**b)** Una suma ponderada  de las entradas seguida de una función de activación.\n"
      ],
      "id": "joined-burden"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iraqi-european"
      },
      "source": [
        "<a name='1.6'></a>\n",
        "## Cuestión 6:  ¿Cuál de estas funciones de activación no debería usarse en una capa oculta (hidden layer)?\n",
        "\n",
        "**a)** `sigmoid`\n",
        "\n",
        "**b)** `tanh`\n",
        "\n",
        "**c)** `relu`\n",
        "\n",
        "**d)** `linear`\n"
      ],
      "id": "iraqi-european"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cardiovascular-attack"
      },
      "source": [
        "Respuesta: **d)** linear"
      ],
      "id": "cardiovascular-attack"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ranging-utilization"
      },
      "source": [
        "<a name='1.7'></a>\n",
        "## Cuestión 7:  ¿Cuál de estas técnicas es efectiva para combatir el overfitting en una red con varias capas ocultas? Ponga todas las que lo sean.\n",
        "\n",
        "**a)** Dropout\n",
        "\n",
        "**b)** Regularización L2.\n",
        "\n",
        "**c)** Aumentar el tamaño del test set.\n",
        "\n",
        "**d)** Aumentar el tamaño del validation set.\n",
        "\n",
        "**e)** Reducir el número de capas de la red.\n",
        "\n",
        "**f)** Data augmentation."
      ],
      "id": "ranging-utilization"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "accessible-trainer"
      },
      "source": [
        ""
      ],
      "id": "accessible-trainer"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "recreational-deposit"
      },
      "source": [
        "<a name='1.8'></a>\n",
        "## Cuestión 8:  Supongamos que queremos entrenar una red para un problema de clasificación de imágenes con las siguientes clases: {'perro','gato','persona'}. ¿Cuántas neuronas y que función de activación debería tener la capa de salida? ¿Qué función de pérdida (loss function) debería usarse?\n"
      ],
      "id": "recreational-deposit"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "confirmed-roulette"
      },
      "source": [
        ""
      ],
      "id": "confirmed-roulette"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "painful-decade"
      },
      "source": [
        "<a name='actividad_2'></a>\n",
        "# Actividad 2: Redes Convolucionales\n",
        "\n",
        "Vamos a usar el dataset [cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html), que son 60000 imágenes de 32x32 a color  con 10 clases diferentes. Para realizar mejor la práctica puede consultar [Introduction_to_CNN.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CNN.ipynb).\n",
        "\n",
        "\n",
        "\n",
        "**Puntuación**: \n",
        "\n",
        "- [Cuestión 1](#2.1): 1 pt\n",
        "- [Cuestión 2](#2.2): 1.5 pt\n",
        "- [Cuestión 3](#2.3): 0.5 pts\n",
        "- [Cuestión 4](#2.4): 0.25 pts\n",
        "- [Cuestión 5](#2.5): 0.25 pts\n",
        "- [Cuestión 6](#2.6): 0.25 pts\n",
        "- [Cuestión 7](#2.7): 0.25 pts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Puede normalizar las imágenes al principio o usar la capa [Rescaling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling):\n",
        "\n",
        "```python\n",
        "tf.keras.layers.experimental.preprocessing.Rescaling(\n",
        "    scale, offset=0.0, name=None, **kwargs\n",
        ")\n",
        "```"
      ],
      "id": "painful-decade"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incorporate-terrorist"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()"
      ],
      "id": "incorporate-terrorist",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brazilian-rhythm"
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "id": "brazilian-rhythm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "extreme-quantum"
      },
      "source": [
        "print('x_train, y_train shapes:', x_train.shape, y_train.shape)\n",
        "print('x_test, y_test shapes:', x_test.shape, y_test.shape)"
      ],
      "id": "extreme-quantum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "living-philosophy"
      },
      "source": [
        "<a name='2.1'></a>\n",
        "## Cuestión 1: Cree una red convolucional con la API funcional con al menos dos capas convolucionales y al menos dos capas de pooling. Utilize sólo [Average Pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) y no añada ninguna regularización."
      ],
      "id": "living-philosophy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atmospheric-sight"
      },
      "source": [
        "inputs = tf.keras.Input(shape=..., name='input')\n",
        "# reescaling = ...\n",
        "\n",
        "# Convolution + pooling layers\n",
        "...\n",
        "\n",
        "# Flattening\n",
        "...\n",
        "\n",
        "# Fully-connected\n",
        "outputs = layers.Dense(...)\n",
        "\n",
        "model = keras.Model(inputs=..., outputs=...)"
      ],
      "id": "atmospheric-sight",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "needed-arena"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "id": "needed-arena",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pursuant-paper"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=25, batch_size=64,\n",
        "                    validation_split=0.15)"
      ],
      "id": "pursuant-paper",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applicable-honduras"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ],
      "id": "applicable-honduras",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "numerous-invite"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "## Cuestión 2: Cree un modelo con la API funcional con un máximo de 2 capas convolucionales y un máximo de 2 capas de pooling. Utilize  [Max Pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) o [Average Pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) y  añada la regularización que quiera. Debe obtener un `Test accuracy > 0.68`"
      ],
      "id": "numerous-invite"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "annual-diploma"
      },
      "source": [
        "inputs = tf.keras.Input(shape=..., name='input')\n",
        "# reescaling = ...\n",
        "\n",
        "# Convolution + pooling layers\n",
        "...\n",
        "\n",
        "# Flattening\n",
        "...\n",
        "\n",
        "# Fully-connected\n",
        "outputs = layers.Dense(...)\n",
        "\n",
        "model = keras.Model(inputs=..., outputs=...)"
      ],
      "id": "annual-diploma",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "indian-messaging"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "id": "indian-messaging",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "functional-republic"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=..., batch_size=...,\n",
        "                    validation_split=0.15, callbacks=lbacks=[...])"
      ],
      "id": "functional-republic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incorrect-completion"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ],
      "id": "incorrect-completion",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optical-arizona"
      },
      "source": [
        "<a name='2.3'></a>\n",
        "## Cuestión 3: Añada data augmentation al principio del modelo\n",
        "\n"
      ],
      "id": "optical-arizona"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "previous-boxing"
      },
      "source": [
        "data_augmentation=... "
      ],
      "id": "previous-boxing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "comprehensive-directive"
      },
      "source": [
        "inputs = tf.keras.Input(shape=..., name='input')\n",
        "data_aug= ...\n",
        "\n",
        "# reescaling = ...\n",
        "\n",
        "# Convolution + pooling layers\n",
        "...\n",
        "\n",
        "# Flattening\n",
        "...\n",
        "\n",
        "# Fully-connected\n",
        "outputs = layers.Dense(...)\n",
        "\n",
        "model = keras.Model(inputs=..., outputs=...)"
      ],
      "id": "comprehensive-directive",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "statutory-covering"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "id": "statutory-covering",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "western-energy"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=..., batch_size=...,\n",
        "                    validation_split=0.15, callbacks=lbacks=[...])"
      ],
      "id": "western-energy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "classical-charm"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ],
      "id": "classical-charm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sweet-implement"
      },
      "source": [
        "<a name='2.4'></a>\n",
        "## Cuestión 4: Cree el mismo  modelo de manera secuencial. No es necesario compilar ni entrenar el modelo"
      ],
      "id": "sweet-implement"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auburn-lawrence"
      },
      "source": [
        "model_seq = tf.keras.models.Sequential()\n",
        "# Código aquí\n",
        "..."
      ],
      "id": "auburn-lawrence",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "present-consortium"
      },
      "source": [
        "<a name='2.5'></a>\n",
        "## Cuestión 5: Si tenenemos una  una imagen de entrada de 300 x 300 a color (RGB) y queremos usar una red densa. Si la primera capa oculta tiene 100 neuronas, ¿Cuántos parámetros tendrá esa capa (sin incluir el bias) ?\n"
      ],
      "id": "present-consortium"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "novel-calcium"
      },
      "source": [
        ""
      ],
      "id": "novel-calcium"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "complicated-positive"
      },
      "source": [
        "<a name='2.6'></a>\n",
        "## Cuestión 6   Ponga  las verdaderas ventajas de las redes convolucionales respecto a las densas\n",
        "\n",
        "**a)** Reducen el número total de parámetros, reduciendo así el overfitting.\n",
        "\n",
        "**b)** Permiten utilizar una misma 'función'  en varias localizaciones de la imagen de entrada, en lugar de aprender una función diferente para cada pixel.\n",
        "\n",
        "**c)** Permiten el uso del transfer learning.\n",
        "\n",
        "**d)** Generalmente son menos profundas, lo que facilita su entrenamiento.\n",
        "\n"
      ],
      "id": "complicated-positive"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dirty-nirvana"
      },
      "source": [
        ""
      ],
      "id": "dirty-nirvana"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "first-toyota"
      },
      "source": [
        "<a name='2.7'></a>\n",
        "## Cuestión 7: Para el procesamiento de series temporales las redes convolucionales no son efectivas, habrá que usar redes recurrentes.\n",
        "\n",
        "- **Verdadero** \n",
        "- **Falso** "
      ],
      "id": "first-toyota"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frequent-seven"
      },
      "source": [
        ""
      ],
      "id": "frequent-seven"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "regional-favorite"
      },
      "source": [
        "<a name='actividad_3'></a>\n",
        "# Actividad 3: Redes Recurrentes\n",
        "\n",
        "\n",
        "- [Cuestión 1](#3.1): 0.5 pt\n",
        "- [Cuestión 2](#3.2): 0.5 pt\n",
        "- [Cuestión 3](#3.3): 0.5 pts\n",
        "- [Cuestión 4](#3.4): 0.25 pts\n",
        "- [Cuestión 5](#3.5): 0.25 pts\n",
        "\n",
        "Vamos a usar un dataset de las temperaturas mínimas diarias en Melbourne. La tarea será la de predecir la temperatura mínima en dos días. Puedes usar técnicas de series temporales vistas en otras asignaturas, pero no es necesario.\n"
      ],
      "id": "regional-favorite"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "empty-value"
      },
      "source": [
        "dataset_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n",
        "data_dir = tf.keras.utils.get_file('daily-min-temperatures.csv', origin=dataset_url)"
      ],
      "id": "empty-value",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "numerous-situation"
      },
      "source": [
        "df = pd.read_csv(data_dir, parse_dates=['Date'])\n",
        "df.head()"
      ],
      "id": "numerous-situation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "copyrighted-madonna"
      },
      "source": [
        "temperatures = df['Temp'].values\n",
        "print('number of samples:', len(temperatures))\n",
        "train_data = temperatures[:3000]\n",
        "test_data = temperatures[3000:]\n",
        "print('number of train samples:', len(train_data))\n",
        "print('number of test samples:', len(test_data))\n",
        "print('firsts trainn samples:', train_data[:10])"
      ],
      "id": "copyrighted-madonna",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adapted-brief"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "## Cuestión 1: Convierta `train_data` y `test_data`  en ventanas de tamaño 5, para predecir el valor en 2 días\n",
        "\n",
        "En la nomenclatura de [Introduction_to_RNN_Time_Series.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb)\n",
        "```python\n",
        "past, future = (5, 2)\n",
        "```\n",
        "\n",
        "Para las primeras 10 muestras de train_data `[20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20. ]` el resultado debería ser:\n",
        "\n",
        "```python\n",
        "x[0] : [20.7, 17.9, 18.8, 14.6, 15.8] , y[0]: 15.8\n",
        "x[1] : [17.9, 18.8, 14.6, 15.8, 15.8] , y[1]: 17.4\n",
        "x[2] : [18.8, 14.6, 15.8, 15.8, 15.8] , y[2]: 21.8\n",
        "x[3] : [14.6, 15.8, 15.8, 15.8, 17.4] , y[3]: 20.             \n",
        "```"
      ],
      "id": "adapted-brief"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conscious-teaching"
      },
      "source": [
        "# windowing function"
      ],
      "id": "conscious-teaching",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joint-annotation"
      },
      "source": [
        "past, future = (5, 2)\n",
        "X_train, y_train = ...\n",
        "X_test, y_test = ..."
      ],
      "id": "joint-annotation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "electrical-junior"
      },
      "source": [
        "<a name='3.2'></a>\n",
        "## Cuestión 2: Cree un modelo recurrente de dos capas GRU para predecir con las ventanas de la cuestión anterior.\n"
      ],
      "id": "electrical-junior"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aboriginal-complaint"
      },
      "source": [
        "inputs = keras.layers.Input(shape=(..., ...))\n",
        "...\n",
        "model = keras.Model(inputs=..., outputs=...)\n",
        "model.compile(...)\n",
        "model.summary()"
      ],
      "id": "aboriginal-complaint",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applicable-longer"
      },
      "source": [
        "es_callback = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",
        ")"
      ],
      "id": "applicable-longer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stone-province"
      },
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "stone-province",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "genetic-guitar"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "## Cuestión 3: Añada más features a la series temporal, por ejemplo `portion_year`. Cree un modelo que mejore al anterior.\n"
      ],
      "id": "genetic-guitar"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prospective-master"
      },
      "source": [
        "## Puede añadir más features\n",
        "df['portion_year'] = df['Date'].dt.dayofyear / 365.0\n",
        "df_multi = df[['Temp', 'portion_year']].copy()\n",
        "\n",
        "## train - test split\n",
        "train_data = df_multi.iloc[:3000].copy()\n",
        "test_data = df_multi.loc[3000:, :].copy()"
      ],
      "id": "prospective-master",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "threaded-sheriff"
      },
      "source": [
        "## Create windows\n",
        "X_train, y_train = ...\n",
        "X_test, y_test = ..."
      ],
      "id": "threaded-sheriff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stable-estate"
      },
      "source": [
        "inputs = keras.layers.Input(shape=(..., ...))\n",
        "...\n",
        "model = keras.Model(inputs=..., outputs=...)\n",
        "model.compile(...)\n",
        "model.summary()"
      ],
      "id": "stable-estate",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "structured-philip"
      },
      "source": [
        "es_callback = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",
        ")"
      ],
      "id": "structured-philip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "assigned-afternoon"
      },
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "assigned-afternoon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "precise-tract"
      },
      "source": [
        "<a name='3.4'></a>\n",
        "## Cuestión 4: ¿En cuáles de estas aplicaciones se usaría un arquitectura 'many-to-one'?\n",
        "\n",
        "**a)** Clasificación de sentimiento en textos\n",
        "\n",
        "**b)** Verificación de voz para iniciar el ordenador.\n",
        "\n",
        "**c)** Generación de música.\n",
        "\n",
        "**d)** Un clasificador que clasifique piezas de música según su autor.\n"
      ],
      "id": "precise-tract"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "professional-mayor"
      },
      "source": [
        ""
      ],
      "id": "professional-mayor"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fallen-error"
      },
      "source": [
        "<a name='3.5'></a>\n",
        "## Cuestión 5: ¿Qué ventajas aporta el uso de word embeddings?\n",
        "\n",
        "**a)** Permiten reducir la dimensión de entrada respecto al one-hot encoding.\n",
        "\n",
        "**b)** Permiten descubrir la similaridad entre palabras de manera más intuitiva que con one-hot encoding.\n",
        "\n",
        "**c)** Son una manera de realizar transfer learning en nlp.\n",
        "\n",
        "**d)** Permiten visualizar las relaciones entre palabras con métodos de reducción de dimensioones como el PCA.\n"
      ],
      "id": "fallen-error"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stylish-polish"
      },
      "source": [
        ""
      ],
      "id": "stylish-polish"
    }
  ]
}