{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "Examen.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerardcebria/Deep-learning-examen/blob/main/Examen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prospective-america"
      },
      "source": [
        "Dado que el entrenamiento de redes neuronales es una tarea  muy costosa, **se recomienda ejecutar el notebooks en [Google Colab](https://colab.research.google.com)**, por supuesto también se puede ejecutar en local.\n",
        "\n",
        "Al entrar en [Google Colab](https://colab.research.google.com) bastará con hacer click en `upload` y subir este notebook. No olvide luego descargarlo en `File->Download .ipynb`\n",
        "\n",
        "**El examen deberá ser entregado con las celdas ejecutadas, si alguna celda no está ejecutadas no se contará.**"
      ],
      "id": "prospective-america"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "novel-stewart"
      },
      "source": [
        "El examen se divide en tres partes, con la puntuación que se indica a continuación. La puntuación máxima será 10.\n",
        "\n",
        "- [Actividad 1: Redes Densas](#actividad_1): 4 pts\n",
        "    - Correcta normalización: máximo de 0.25 pts\n",
        "    - [Cuestión 1](#1.1): 1 pt\n",
        "    - [Cuestión 2](#1.2): 1 pt\n",
        "    - [Cuestión 3](#1.3): 0.5 pts\n",
        "    - [Cuestión 4](#1.4): 0.25 pts\n",
        "    - [Cuestión 5](#1.5): 0.25 pts\n",
        "    - [Cuestión 6](#1.6): 0.25 pts\n",
        "    - [Cuestión 7](#1.7): 0.25 pts\n",
        "    - [Cuestión 8](#1.8): 0.25 pts\n",
        "\n",
        "\n",
        "- [Actividad 2: Redes Convolucionales](#actividad_2): 4 pts\n",
        "    - [Cuestión 1](#2.1): 1 pt\n",
        "    - [Cuestión 2](#2.2): 1.5 pt\n",
        "    - [Cuestión 3](#2.3): 0.5 pts\n",
        "    - [Cuestión 4](#2.4): 0.25 pts\n",
        "    - [Cuestión 5](#2.5): 0.25 pts\n",
        "    - [Cuestión 6](#2.6): 0.25 pts\n",
        "    - [Cuestión 7](#2.7): 0.25 pts\n",
        "    \n",
        "    \n",
        "- [Actividad 3: Redes Recurrentes](#actividad_3): 2 pts\n",
        "    - [Cuestión 1](#3.1): 0.5 pt\n",
        "    - [Cuestión 2](#3.2): 0.5 pt\n",
        "    - [Cuestión 3](#3.3): 0.5 pts\n",
        "    - [Cuestión 4](#3.4): 0.25 pts\n",
        "    - [Cuestión 5](#3.5): 0.25 pts\n",
        "\n"
      ],
      "id": "novel-stewart"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prompt-developer"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "id": "prompt-developer",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vocal-correction"
      },
      "source": [
        "<a name='actividad_1'></a>\n",
        "# Actividad 1: Redes Densas\n",
        "\n",
        "Para esta primera actividad vamos a utilizar el [boston housing dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html). Con el que trataremos de predecir el precio de una casa con 13 features.\n",
        "\n",
        "**Puntuación**: \n",
        "\n",
        "Normalizar las features correctamente (x_train, x_test): 0.1 pts , 0.25 si se normalizan con el [Normalization layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) de Keras. Ejemplo de uso: [Introduction_to_RNN_Time_Series](https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb)\n",
        "\n",
        "```python\n",
        "tf.keras.layers.experimental.preprocessing.Normalization(\n",
        "    axis=-1, dtype=None, mean=None, variance=None, **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "- Correcta normalización: máximo de 0.25 pts\n",
        "- [Cuestión 1](#1.1): 1 pt\n",
        "- [Cuestión 2](#1.2): 1 pt\n",
        "- [Cuestión 3](#1.3): 0.5 pts\n",
        "- [Cuestión 4](#1.4): 0.25 pts\n",
        "- [Cuestión 5](#1.5): 0.25 pts\n",
        "- [Cuestión 6](#1.6): 0.25 pts\n",
        "- [Cuestión 7](#1.7): 0.25 pts\n",
        "- [Cuestión 8](#1.8): 0.25 pts\n",
        "\n"
      ],
      "id": "vocal-correction"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "presidential-milan",
        "outputId": "d4226d67-046f-4c9b-a0c4-c7249ffc58a5"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path='boston_housing.npz',\n",
        "    test_split=0.2,\n",
        ")\n",
        "print('x_train, y_train shapes:', x_train.shape, y_train.shape)\n",
        "print('x_test, y_test shapes:', x_train.shape, y_train.shape)\n",
        "print('Some prices: ', y_train[:5])"
      ],
      "id": "presidential-milan",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "x_train, y_train shapes: (404, 13) (404,)\n",
            "x_test, y_test shapes: (404, 13) (404,)\n",
            "Some prices:  [15.2 42.3 50.  21.1 17.7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "painted-extreme"
      },
      "source": [
        "## Si quiere, puede normalizar las features"
      ],
      "id": "painted-extreme",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "underlying-planner"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "## Cuestión 1: Cree un modelo secuencial que contenga 4 capas ocultas(hidden layers), con más de 60 neuronas  por capa, sin regularización y obtenga los resultados.\n",
        "\n",
        "Puntuación: \n",
        "- Obtener el modelo correcto: 0.8 pts\n",
        "- Compilar el modelo: 0.1pts\n",
        "- Acertar con la función de pérdida: 0.1 pts"
      ],
      "id": "underlying-planner"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "working-shade",
        "outputId": "ed17c562-0476-4d38-9dcd-e383077da4ec"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "# Código aquí\n",
        "inputs = keras.Input(shape=(13,))\n",
        "l_1 = layers.Dense(61, activation='sigmoid',\n",
        "                       name='layer_1')(inputs)\n",
        "l_2 = layers.Dense(61, activation='sigmoid',\n",
        "                       name='layer_2')(l_1)\n",
        "l_3 = layers.Dense(61, activation='sigmoid',\n",
        "                       name='layer_3')(l_2)\n",
        "l_4 = layers.Dense(61, activation='sigmoid',\n",
        "                       name='layer_4')(l_3)\n",
        "\n",
        "outputs = layers.Dense(1, name='output_layer')(layer_2)\n",
        "\n",
        "model.add(keras.layers.Dense(61, input_shape=(13, ), activation='sigmoid'))\n",
        "model.add(keras.layers.Dense(61, activation='sigmoid'))"
      ],
      "id": "working-shade",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2e615ef94982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Código aquí\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mobile-change"
      },
      "source": [
        "# Compilación del modelo\n",
        "# Código aquí\n",
        "model.compile(...)"
      ],
      "id": "mobile-change",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rotary-credits"
      },
      "source": [
        "# No modifique el código\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=200,\n",
        "          batch_size=32,\n",
        "          validation_split=0.2,\n",
        "          verbose=1)"
      ],
      "id": "rotary-credits",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "descending-letters"
      },
      "source": [
        "# No modifique el código\n",
        "results = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "descending-letters",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raised-delivery"
      },
      "source": [
        "<a name='1.2'></a>\n",
        "## Cuestión 2: Utilice el mismo modelo de la cuestión anterior pero añadiendo al menos dos técnicas distinas de regularización.\n",
        "\n",
        "Ejemplos de regularización: [Prevent_Overfitting.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Prevent_Overfitting.ipynb)\n",
        "\n",
        "Puntuación:\n",
        "\n",
        "- Obtener el modelo con la regularización: 0.8 pts\n",
        "- Obtener un `test loss` inferior al anterior: 0.2 pts\n"
      ],
      "id": "raised-delivery"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hired-ground"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "# Código aquí\n",
        "..."
      ],
      "id": "hired-ground",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "focal-traffic"
      },
      "source": [
        "# Compilación del modelo\n",
        "# Código aquí\n",
        "model.compile(...)"
      ],
      "id": "focal-traffic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "338f8622"
      },
      "source": [
        "batch_size=..."
      ],
      "id": "338f8622",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prostate-instrumentation"
      },
      "source": [
        "# No modifique el código\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=200,\n",
        "          batch_size=batch_size,\n",
        "          validation_split=0.2,\n",
        "          verbose=1)"
      ],
      "id": "prostate-instrumentation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "friendly-powell"
      },
      "source": [
        "# No modifique el código\n",
        "results = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "friendly-powell",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "british-vegetation"
      },
      "source": [
        "<a name='1.3'></a>\n",
        "## Cuestión 3: Utilice el mismo modelo de la cuestión anterior pero añadiendo un callback de early stopping. Obtenga un test loss inferior al del modelo anterior"
      ],
      "id": "british-vegetation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "precise-finish"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "# Código aquí\n",
        "..."
      ],
      "id": "precise-finish",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blond-telephone"
      },
      "source": [
        "# Compilación del modelo\n",
        "# Código aquí\n",
        "model.compile(...)"
      ],
      "id": "blond-telephone",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "subsequent-roads"
      },
      "source": [
        "## definir el early stopping callback\n",
        "# Código aquí\n",
        "...\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=200,\n",
        "          batch_size=32,\n",
        "          validation_split=0.2,\n",
        "          verbose=1,\n",
        "          callbacks=[...]) # Código aquí"
      ],
      "id": "subsequent-roads",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pressing-object"
      },
      "source": [
        "# No modifique el código\n",
        "results = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "pressing-object",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "addressed-lesbian"
      },
      "source": [
        "<a name='1.4'></a>\n",
        "## Cuestión 4: ¿Podría haberse usado otra función de activación de la neurona de salida? En caso afirmativo especifíquela."
      ],
      "id": "addressed-lesbian"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruled-silicon"
      },
      "source": [
        ""
      ],
      "id": "ruled-silicon"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "robust-christianity"
      },
      "source": [
        "<a name='1.5'></a>\n",
        "## Cuestión 5:  ¿Qué es lo que una neurona calcula?\n",
        "\n",
        "**a)** Una función de activación seguida de una suma ponderada  de las entradas.\n",
        "\n",
        "**b)** Una suma ponderada  de las entradas seguida de una función de activación.\n",
        "\n",
        "**c)** Una función de pérdida, definida sobre el target.\n",
        "\n",
        "**d)** Ninguna  de las anteriores es correcta\n"
      ],
      "id": "robust-christianity"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joined-burden"
      },
      "source": [
        "Respuesta:\n",
        "**b)** Una suma ponderada  de las entradas seguida de una función de activación.\n"
      ],
      "id": "joined-burden"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iraqi-european"
      },
      "source": [
        "<a name='1.6'></a>\n",
        "## Cuestión 6:  ¿Cuál de estas funciones de activación no debería usarse en una capa oculta (hidden layer)?\n",
        "\n",
        "**a)** `sigmoid`\n",
        "\n",
        "**b)** `tanh`\n",
        "\n",
        "**c)** `relu`\n",
        "\n",
        "**d)** `linear`\n"
      ],
      "id": "iraqi-european"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cardiovascular-attack"
      },
      "source": [
        "Respuesta: **d)** linear"
      ],
      "id": "cardiovascular-attack"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ranging-utilization"
      },
      "source": [
        "<a name='1.7'></a>\n",
        "## Cuestión 7:  ¿Cuál de estas técnicas es efectiva para combatir el overfitting en una red con varias capas ocultas? Ponga todas las que lo sean.\n",
        "\n",
        "**a)** Dropout\n",
        "\n",
        "**b)** Regularización L2.\n",
        "\n",
        "**c)** Aumentar el tamaño del test set.\n",
        "\n",
        "**d)** Aumentar el tamaño del validation set.\n",
        "\n",
        "**e)** Reducir el número de capas de la red.\n",
        "\n",
        "**f)** Data augmentation."
      ],
      "id": "ranging-utilization"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "accessible-trainer"
      },
      "source": [
        ""
      ],
      "id": "accessible-trainer"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "recreational-deposit"
      },
      "source": [
        "<a name='1.8'></a>\n",
        "## Cuestión 8:  Supongamos que queremos entrenar una red para un problema de clasificación de imágenes con las siguientes clases: {'perro','gato','persona'}. ¿Cuántas neuronas y que función de activación debería tener la capa de salida? ¿Qué función de pérdida (loss function) debería usarse?\n"
      ],
      "id": "recreational-deposit"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "confirmed-roulette"
      },
      "source": [
        ""
      ],
      "id": "confirmed-roulette"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "painful-decade"
      },
      "source": [
        "<a name='actividad_2'></a>\n",
        "# Actividad 2: Redes Convolucionales\n",
        "\n",
        "Vamos a usar el dataset [cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html), que son 60000 imágenes de 32x32 a color  con 10 clases diferentes. Para realizar mejor la práctica puede consultar [Introduction_to_CNN.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CNN.ipynb).\n",
        "\n",
        "\n",
        "\n",
        "**Puntuación**: \n",
        "\n",
        "- [Cuestión 1](#2.1): 1 pt\n",
        "- [Cuestión 2](#2.2): 1.5 pt\n",
        "- [Cuestión 3](#2.3): 0.5 pts\n",
        "- [Cuestión 4](#2.4): 0.25 pts\n",
        "- [Cuestión 5](#2.5): 0.25 pts\n",
        "- [Cuestión 6](#2.6): 0.25 pts\n",
        "- [Cuestión 7](#2.7): 0.25 pts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Puede normalizar las imágenes al principio o usar la capa [Rescaling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling):\n",
        "\n",
        "```python\n",
        "tf.keras.layers.experimental.preprocessing.Rescaling(\n",
        "    scale, offset=0.0, name=None, **kwargs\n",
        ")\n",
        "```"
      ],
      "id": "painful-decade"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incorporate-terrorist"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()"
      ],
      "id": "incorporate-terrorist",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brazilian-rhythm"
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "id": "brazilian-rhythm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "extreme-quantum"
      },
      "source": [
        "print('x_train, y_train shapes:', x_train.shape, y_train.shape)\n",
        "print('x_test, y_test shapes:', x_test.shape, y_test.shape)"
      ],
      "id": "extreme-quantum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "living-philosophy"
      },
      "source": [
        "<a name='2.1'></a>\n",
        "## Cuestión 1: Cree una red convolucional con la API funcional con al menos dos capas convolucionales y al menos dos capas de pooling. Utilize sólo [Average Pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) y no añada ninguna regularización."
      ],
      "id": "living-philosophy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atmospheric-sight"
      },
      "source": [
        "inputs = tf.keras.Input(shape=..., name='input')\n",
        "# reescaling = ...\n",
        "\n",
        "# Convolution + pooling layers\n",
        "...\n",
        "\n",
        "# Flattening\n",
        "...\n",
        "\n",
        "# Fully-connected\n",
        "outputs = layers.Dense(...)\n",
        "\n",
        "model = keras.Model(inputs=..., outputs=...)"
      ],
      "id": "atmospheric-sight",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "needed-arena"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "id": "needed-arena",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pursuant-paper"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=25, batch_size=64,\n",
        "                    validation_split=0.15)"
      ],
      "id": "pursuant-paper",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applicable-honduras"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ],
      "id": "applicable-honduras",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "numerous-invite"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "## Cuestión 2: Cree un modelo con la API funcional con un máximo de 2 capas convolucionales y un máximo de 2 capas de pooling. Utilize  [Max Pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) o [Average Pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) y  añada la regularización que quiera. Debe obtener un `Test accuracy > 0.68`"
      ],
      "id": "numerous-invite"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "annual-diploma"
      },
      "source": [
        "inputs = tf.keras.Input(shape=..., name='input')\n",
        "# reescaling = ...\n",
        "\n",
        "# Convolution + pooling layers\n",
        "...\n",
        "\n",
        "# Flattening\n",
        "...\n",
        "\n",
        "# Fully-connected\n",
        "outputs = layers.Dense(...)\n",
        "\n",
        "model = keras.Model(inputs=..., outputs=...)"
      ],
      "id": "annual-diploma",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "indian-messaging"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "id": "indian-messaging",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "functional-republic"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=..., batch_size=...,\n",
        "                    validation_split=0.15, callbacks=lbacks=[...])"
      ],
      "id": "functional-republic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incorrect-completion"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ],
      "id": "incorrect-completion",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optical-arizona"
      },
      "source": [
        "<a name='2.3'></a>\n",
        "## Cuestión 3: Añada data augmentation al principio del modelo\n",
        "\n"
      ],
      "id": "optical-arizona"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "previous-boxing"
      },
      "source": [
        "data_augmentation=... "
      ],
      "id": "previous-boxing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "comprehensive-directive"
      },
      "source": [
        "inputs = tf.keras.Input(shape=..., name='input')\n",
        "data_aug= ...\n",
        "\n",
        "# reescaling = ...\n",
        "\n",
        "# Convolution + pooling layers\n",
        "...\n",
        "\n",
        "# Flattening\n",
        "...\n",
        "\n",
        "# Fully-connected\n",
        "outputs = layers.Dense(...)\n",
        "\n",
        "model = keras.Model(inputs=..., outputs=...)"
      ],
      "id": "comprehensive-directive",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "statutory-covering"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "id": "statutory-covering",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "western-energy"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=..., batch_size=...,\n",
        "                    validation_split=0.15, callbacks=lbacks=[...])"
      ],
      "id": "western-energy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "classical-charm"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))"
      ],
      "id": "classical-charm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sweet-implement"
      },
      "source": [
        "<a name='2.4'></a>\n",
        "## Cuestión 4: Cree el mismo  modelo de manera secuencial. No es necesario compilar ni entrenar el modelo"
      ],
      "id": "sweet-implement"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auburn-lawrence"
      },
      "source": [
        "model_seq = tf.keras.models.Sequential()\n",
        "# Código aquí\n",
        "..."
      ],
      "id": "auburn-lawrence",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "present-consortium"
      },
      "source": [
        "<a name='2.5'></a>\n",
        "## Cuestión 5: Si tenenemos una  una imagen de entrada de 300 x 300 a color (RGB) y queremos usar una red densa. Si la primera capa oculta tiene 100 neuronas, ¿Cuántos parámetros tendrá esa capa (sin incluir el bias) ?\n"
      ],
      "id": "present-consortium"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "novel-calcium"
      },
      "source": [
        ""
      ],
      "id": "novel-calcium"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "complicated-positive"
      },
      "source": [
        "<a name='2.6'></a>\n",
        "## Cuestión 6   Ponga  las verdaderas ventajas de las redes convolucionales respecto a las densas\n",
        "\n",
        "**a)** Reducen el número total de parámetros, reduciendo así el overfitting.\n",
        "\n",
        "**b)** Permiten utilizar una misma 'función'  en varias localizaciones de la imagen de entrada, en lugar de aprender una función diferente para cada pixel.\n",
        "\n",
        "**c)** Permiten el uso del transfer learning.\n",
        "\n",
        "**d)** Generalmente son menos profundas, lo que facilita su entrenamiento.\n",
        "\n"
      ],
      "id": "complicated-positive"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dirty-nirvana"
      },
      "source": [
        ""
      ],
      "id": "dirty-nirvana"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "first-toyota"
      },
      "source": [
        "<a name='2.7'></a>\n",
        "## Cuestión 7: Para el procesamiento de series temporales las redes convolucionales no son efectivas, habrá que usar redes recurrentes.\n",
        "\n",
        "- **Verdadero** \n",
        "- **Falso** "
      ],
      "id": "first-toyota"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frequent-seven"
      },
      "source": [
        ""
      ],
      "id": "frequent-seven"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "regional-favorite"
      },
      "source": [
        "<a name='actividad_3'></a>\n",
        "# Actividad 3: Redes Recurrentes\n",
        "\n",
        "\n",
        "- [Cuestión 1](#3.1): 0.5 pt\n",
        "- [Cuestión 2](#3.2): 0.5 pt\n",
        "- [Cuestión 3](#3.3): 0.5 pts\n",
        "- [Cuestión 4](#3.4): 0.25 pts\n",
        "- [Cuestión 5](#3.5): 0.25 pts\n",
        "\n",
        "Vamos a usar un dataset de las temperaturas mínimas diarias en Melbourne. La tarea será la de predecir la temperatura mínima en dos días. Puedes usar técnicas de series temporales vistas en otras asignaturas, pero no es necesario.\n"
      ],
      "id": "regional-favorite"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "empty-value"
      },
      "source": [
        "dataset_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n",
        "data_dir = tf.keras.utils.get_file('daily-min-temperatures.csv', origin=dataset_url)"
      ],
      "id": "empty-value",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "numerous-situation"
      },
      "source": [
        "df = pd.read_csv(data_dir, parse_dates=['Date'])\n",
        "df.head()"
      ],
      "id": "numerous-situation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "copyrighted-madonna"
      },
      "source": [
        "temperatures = df['Temp'].values\n",
        "print('number of samples:', len(temperatures))\n",
        "train_data = temperatures[:3000]\n",
        "test_data = temperatures[3000:]\n",
        "print('number of train samples:', len(train_data))\n",
        "print('number of test samples:', len(test_data))\n",
        "print('firsts trainn samples:', train_data[:10])"
      ],
      "id": "copyrighted-madonna",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adapted-brief"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "## Cuestión 1: Convierta `train_data` y `test_data`  en ventanas de tamaño 5, para predecir el valor en 2 días\n",
        "\n",
        "En la nomenclatura de [Introduction_to_RNN_Time_Series.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb)\n",
        "```python\n",
        "past, future = (5, 2)\n",
        "```\n",
        "\n",
        "Para las primeras 10 muestras de train_data `[20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20. ]` el resultado debería ser:\n",
        "\n",
        "```python\n",
        "x[0] : [20.7, 17.9, 18.8, 14.6, 15.8] , y[0]: 15.8\n",
        "x[1] : [17.9, 18.8, 14.6, 15.8, 15.8] , y[1]: 17.4\n",
        "x[2] : [18.8, 14.6, 15.8, 15.8, 15.8] , y[2]: 21.8\n",
        "x[3] : [14.6, 15.8, 15.8, 15.8, 17.4] , y[3]: 20.             \n",
        "```"
      ],
      "id": "adapted-brief"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conscious-teaching"
      },
      "source": [
        "# windowing function"
      ],
      "id": "conscious-teaching",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joint-annotation"
      },
      "source": [
        "past, future = (5, 2)\n",
        "X_train, y_train = ...\n",
        "X_test, y_test = ..."
      ],
      "id": "joint-annotation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "electrical-junior"
      },
      "source": [
        "<a name='3.2'></a>\n",
        "## Cuestión 2: Cree un modelo recurrente de dos capas GRU para predecir con las ventanas de la cuestión anterior.\n"
      ],
      "id": "electrical-junior"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aboriginal-complaint"
      },
      "source": [
        "inputs = keras.layers.Input(shape=(..., ...))\n",
        "...\n",
        "model = keras.Model(inputs=..., outputs=...)\n",
        "model.compile(...)\n",
        "model.summary()"
      ],
      "id": "aboriginal-complaint",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applicable-longer"
      },
      "source": [
        "es_callback = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",
        ")"
      ],
      "id": "applicable-longer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stone-province"
      },
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "stone-province",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "genetic-guitar"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "## Cuestión 3: Añada más features a la series temporal, por ejemplo `portion_year`. Cree un modelo que mejore al anterior.\n"
      ],
      "id": "genetic-guitar"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prospective-master"
      },
      "source": [
        "## Puede añadir más features\n",
        "df['portion_year'] = df['Date'].dt.dayofyear / 365.0\n",
        "df_multi = df[['Temp', 'portion_year']].copy()\n",
        "\n",
        "## train - test split\n",
        "train_data = df_multi.iloc[:3000].copy()\n",
        "test_data = df_multi.loc[3000:, :].copy()"
      ],
      "id": "prospective-master",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "threaded-sheriff"
      },
      "source": [
        "## Create windows\n",
        "X_train, y_train = ...\n",
        "X_test, y_test = ..."
      ],
      "id": "threaded-sheriff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stable-estate"
      },
      "source": [
        "inputs = keras.layers.Input(shape=(..., ...))\n",
        "...\n",
        "model = keras.Model(inputs=..., outputs=...)\n",
        "model.compile(...)\n",
        "model.summary()"
      ],
      "id": "stable-estate",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "structured-philip"
      },
      "source": [
        "es_callback = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",
        ")"
      ],
      "id": "structured-philip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "assigned-afternoon"
      },
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ],
      "id": "assigned-afternoon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "precise-tract"
      },
      "source": [
        "<a name='3.4'></a>\n",
        "## Cuestión 4: ¿En cuáles de estas aplicaciones se usaría un arquitectura 'many-to-one'?\n",
        "\n",
        "**a)** Clasificación de sentimiento en textos\n",
        "\n",
        "**b)** Verificación de voz para iniciar el ordenador.\n",
        "\n",
        "**c)** Generación de música.\n",
        "\n",
        "**d)** Un clasificador que clasifique piezas de música según su autor.\n"
      ],
      "id": "precise-tract"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "professional-mayor"
      },
      "source": [
        ""
      ],
      "id": "professional-mayor"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fallen-error"
      },
      "source": [
        "<a name='3.5'></a>\n",
        "## Cuestión 5: ¿Qué ventajas aporta el uso de word embeddings?\n",
        "\n",
        "**a)** Permiten reducir la dimensión de entrada respecto al one-hot encoding.\n",
        "\n",
        "**b)** Permiten descubrir la similaridad entre palabras de manera más intuitiva que con one-hot encoding.\n",
        "\n",
        "**c)** Son una manera de realizar transfer learning en nlp.\n",
        "\n",
        "**d)** Permiten visualizar las relaciones entre palabras con métodos de reducción de dimensioones como el PCA.\n"
      ],
      "id": "fallen-error"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stylish-polish"
      },
      "source": [
        ""
      ],
      "id": "stylish-polish"
    }
  ]
}